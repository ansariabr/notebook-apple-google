Thurston: You know

where we're going?

Osterloh: We have this idea that,

in the future,

you can get help

wherever you are,

for whatever you need.

It's almost like it's in the air.

Thurston: Hey. What's up, man?

Osterloh: How's it going?

Have you seen any of this stuff?

Thurston: Never been here.

Osterloh: Come on in.

Thurston: Thank you.

Kwee: I'm not necessarily

designing this for myself.

I'm designing it

for people out there

that really could use

an assistant in their home.

MacIntosh: There's a lot of sensors,

and processors, and machine learning.

Things that are uniquely Google.

Olsson: When you combine

the ultimate piece of technology

and something so human

that's where magic happens.

Giusti: This vision, to me,

it's really compelling,

'cause we can create a new generation

of products that truly helpful.

Poupyrev: It helps you,

from the background...

Thurston: Right.

Poupyrev: Run in the foreground,

and the foreground is your life.

Thurston: Big picture.

What's the endgame?

Osterloh: It's about making it

easier every day.

Thurston: Making what easier?

Osterloh: Life.

Thurston: Making life easier?

Osterloh: Yes.

Thurston: Let's take a look.

Person: Here we go.

Osterloh: Good morning.

Morning. Thanks so much

for joining us here, in New York City,

and for those on the live stream

for joining us, around the world.

Thanks so much.

We're gonna spend the next hour

talking about the problems

we're working to solve for our users

and the ways we're delivering help

for the way people

need it when they need it.

We'll also take you into our labs

with writer and cultural commentator

Baratunde Thurston, to hear

from the folks at Google

who personally develop, design,

and bring these products to life.

Now, if you look across

all of Google's products,

from Search to Maps, Gmail to Photos,

our mission is to bring

a more helpful Google for you.

Creating tools that help you

increase your knowledge,

success, health,

and happiness.

Now, when we apply that mission

to hardware and services

it means creating products

like these.

New Pixel phones, wearables, laptops,

and Nest devices for the home.

Each one is thoughtfully

and responsibly designed,

to help you in your every day

without intruding on your life.

Now, in the mobile era,

smartphones changed the world.

It's super useful to have a powerful

computer everywhere you are,

but it's even more useful when computing

is anywhere you need it.

Always available to help.

Now, you heard me talk

about this idea with Baratunde

that helpful computing

can be all around you.

Ambient computing.

Your devices work together

with services and AI,

so help is anywhere

you want it, and it's fluid.

The technology just fades into

the background when you don't need it.

So the devices aren't

the center of the system.

You are. That's our vision

for ambient computing.

The Google Assistant plays

a critical role here.

It pulls everything together

and gives you a familiar,

natural way

to get the help you need.

Our users tell us they find

the Google Assistant to be smart,

user friendly,

and reliable.

And that's so important

for ambient technology.

Interactions have to feel

natural and intuitive.

Here's an example.

If you want to listen to music,

the experience should be the same

whether you're in the kitchen,

you're driving in your car,

or hanging out with friends.

No matter what you're doing,

you should just be able to say

the name of a song,

and the music just plays.

Without you having to pull out a phone,

and tap on screens, or push buttons.

So think about how this vision

plays out in the home

where ambient technology

can make life so much easier.

When you wake up

in the morning your home

knows what you need

to start your day.

You can get your commute,

find out when your first meeting starts,

maybe play some music on whatever

speaker or screen is nearby.

And when you leave your house

your lights, thermostat, door locks,

security cameras--they all

just know what to do.

And your devices go silent

and turn off notifications at night

when you want to relax

without technology interrupting

or distracting you.

So throughout your home technology

works as a single system,

instead of a bunch of devices

doing their own thing.

Now, we can bring this ambient

computing vision to gaming, as well.

With Stadia, our new generation

cloud gaming platform,

we're aiming to deliver

the best games ever made

to almost any screen

in your life.

So I'm excited to share

an update with y'all.

Stadia will be available

on November 19th,

so you'll be able to play games

wherever you want.

On your TV, your laptop,

even your Pixel,

which will be the first phone

to support Stadia when it launches.

We're also creating a few areas

to create more human

interactions with technology,

like motion sense and the new

Google Assistant for Pixel 4.

So instead of being glued

to your phone,

you can use quick gestures

and voice commands

and then get back to your day.

That push for quicker,

more natural interactions

is leading us

in new hardware directions, too,

extending the phone's

capabilities in new ways.

Let's take a look.

Thurston: This is clearly

a time machine.

Olsson: Yeah, exactly.

Thurston: And you're pretending

to use it to test ear buds.

That's a great cover story.

Right.

Left. Up. Down.

Hello.

Olsson: Hi.

Thurston: Isabelle?

I know you and your team

led the design

for the ear buds.

Olsson: We really wanted it

to just be a simple,

tiny little dot

floating in your ear.

What is a simpler form than a circle,

and how insanely tiny can we make it?

'Cause there's, like,

two computers in there.

Thurston: Those are floating

computers in your head?

Olsson: Yes, yeah.

Thurston: Do you remember how you felt

when you first got the design brief

for what these ear buds

were supposed to do?

Yip: I think it's crazy.

MacIntosh: Certainly, the assembly is

the really challenging part of this.

All of these pieces have to go together

with sub-millimeter precision.

I don't think I would have imagined

we'd be able to build things

with this kind of

processing power this small.

There's a lot of sensors

and processors.

Little bit like building

a ship in the bottle.

What we've managed to do here

is not just make great headphones,

but really putting in all of the other

things that are uniquely Google

about this--the ability

to process your voice.

Thurston: Hello.

MacIntosh: And to make a call clear,

even when you're riding

a bicycle down the sidewalk.

Thurston: Yeah, yeah. Okay.

MacIntosh: A lot of software.

A lot of machine learning.

It's the magic

that powers the product.

Turns a great set of headphones

into a Google set of headphones.

Osterloh: All right.

That was a sneak peek

at the all-new Google Pixel buds.

So you can start to get an idea

of what ambient computing feels like.

With Pixel buds help is there

when you want it,

and the experience just comes to you,

even when your phone's not in your hand.

For instance, you can get

hands-free access to the assistant.

So instead of turning to your phone

for quick tasks, you can just say,

"Hey, Google," and ask the assistant

for whatever you need.

Resume your podcast,

send a quick text, get directions,

or even understand another

language with Google Translate.

Pixel buds even have a long-range

Bluetooth connection

which keeps you connected,

even when your phone

isn't by your side,

so you can wear them in the yard

when your phone might be charging inside

or leave your phone in a locker,

if you're working out in a gym.

Indoors, Pixel buds'll stay

connected up to three rooms away,

and outside, they'll work across

an entire football field.

Of course, Pixel buds

won't be truly helpful,

unless they're also

great headphones.

They have to have

excellent sound quality.

They've gotta be comfortable

to wear all the time,

and they need to last

long enough to be useful.

That's a lot to ask

of a pair of headphones,

especially because they also

need to be unobtrusive too.

So we did some intricate

origami with Pixel buds,

to make sure everything fit.

Custom speakers.

Sensors. Custom battery.

That's usually what makes

these wireless ear buds

stick so far out of your ears,

but Pixel buds gives you

plenty of battery life

to get through your day.

You'll have five hours of continuous

listening time on a single charge

and up to 24 hours when you're using

a wireless charging case.

Now, even with all those components

and long battery life,

you can see Pixel buds

fits almost flush with the ear.

They're so small and light it's easy

to forget you're wearing 'em.

At the same time, Pixel buds

deliver excellent sound quality.

Now, you typically

have to choose

between great sound and awareness

of the world around you,

but Pixel buds gives you both

with a unique hybrid design.

The ear buds gently seal the ear

for rich bass and clear highs,

and the spatial vent underneath reduces

that plugged-ear feeling

and lets through just the right amount

of environmental sound.

On the software side,

Pixel buds respond to your surroundings

with a new adaptive sound.

The volume dynamically adjusts,

as you move from the quiet of your home

to a subway or a noisy cafe,

and you don't have to constantly

raise or lower the volume.

When you're on a call, beam-forming

mikes focus on your voice

while voice accelerometers detect

speech through your jawbone,

so a loud restaurant

or a windy day

won't get in the way

of your conversation.

Pixel buds will be available

in the spring of next year,

and we'll share more details

in the coming months,

including a few of

the helpful experiences

that make good use of the

on-device machine learning chips.

So as you can see, this ambient

computing era's going to bring

all kinds of new interfaces,

services, and devices,

but it's also introducing

new challenges.

When computing's always available

designing for security and privacy

becomes more important

than ever.

You need to know

that your data's safe.

Protecting your data

and respecting your privacy

are at the core

of everything we do.

We've designed strong protections

across our hardware family,

like the Titan security chip

in our phones and laptops.

Titan protects your most personal

on-device information,

your OS data, passwords,

even information in third-party apps.

And we know that privacy is personal

which is why you have the controls,

so that you can choose the settings

you want that are right for you.

We make it easy to access

simple on/off controls,

including turning cameras

and mikes on your Nest devices off.

And you can now delete

assistant data just by asking.

Everything is designed

with your privacy in mind,

and you'll see examples of that

throughout today's presentation.

Now, we're also gonna

talk today about our work

to create more sustainable

products and processes.

Developing sustainable solutions

to mass production and consumption

is one of the biggest

challenges we face today,

as an industry.

It impacts all of us,

and it will for generations to come.

Now, we believe

Google has both the ability

and the responsibility

to create systemic change.

As a company, we've been focused

on sustainability for a long time.

Google's operations have been

carbon neutral since 2007,

and for the past two years,

we've matched all of Google's

energy consumption

with 100%

renewable energy.

And we're continuing to expand access

to clean energy to more people,

including our suppliers

and the communities

where our products are made.

So today we're announcing

that Google's committing to invest

another $150 million

in renewable energy projects

in key manufacturing regions.

Our investment...

Our investment, alongside financial

and manufacturing partners,

aims to catalyze

$1.5 billion of capital.

Now, this'll generate approximately

the same amount of renewable energy

as the electricity

used to manufacture

Made by Google products.

So when you choose

to buy hardware products

from Google you're contributing

to bringing renewable energy

to communities

around the world.

Sustainable, secure and private,

and of course helpful.

That's the Google way

to make hardware and services.

Now, we're excited

to share with you

how we build these principles

into our products,

and here's Ivy Ross,

who leads our design team,

who's gonna talk about

some of our recent work

in responsible

manufacturing and design.

Ross: Thanks, Rick.

I'm happy to be back in New York,

to discuss our design

philosophy at Google

and tell you about a few things

that we've been working on.

I grew up not too far

from here, in the Bronx,

and my dad was

a designer--industrial designer, too,

and he worked for the legendary

industrial designer Raymond Loewy,

on automobiles and a lot

of other consumer goods.

When I was little he even made me

my own little roadster.

I can remember spending hours

in his studio, as a kid,

tinkering with different

tools and materials.

And something I learned early on

is that, at its core,

design is about

solving problems for people.

Whether you're designing a building,

an automobile, packaging,

or even a phone the goal

is to create unique solutions

to the world's challenges.

And sustainability

is one of the fundamental

challenges of our generation.

You know, when you look

at how most things are made today

it just doesn't make sense.

In all too many cases,

devices are manufactured

with dirty energy,

from precious minerals

and materials

that are rapidly depleted

and with technology

that becomes obsolete in a short time

and then thrown away.

Right now, we're truly looking

at sustainability from every angle.

For years, we've been pushing

what's possible in design,

manufacturing,

and new materials.

We've been able to include

recycled plastics

in products like Chromecast

and the new Stadia controller.

And today, I'm happy to share

that all of our Nest products

launching in 2019 include

recycled plastics.

Instead of these materials

ending up in the ocean or in landfill,

we're giving them a new life.

We've designed and engineered

the fabric on our Nest mini speaker

so it's made from 100%

recycled plastic bottles.

A single half-liter bottle

produces enough textiles to cover

more than two Nest minis,

and we didn't compromise

on aesthetics or function.

We created beautiful

recycled fabrics in colors

that blend into your home while hitting

the same rigorous technical

and acoustical requirements.

We continue to focus

on products

that empower people to reduce their own

environmental impact, as well.

Our Nest team has been at the forefront

of these efforts since 2011,

and as of this month,

Nest thermostats have helped consumers

save more than 41 billion

kilowatts hours of energy.

Enough to power all of Denver's

electricity needs for six years.

Rick just filled you in on our

new renewable energy investment,

and as of last month,

Google is offsetting 100% of the carbon

generated by our shipping partners

for all customer orders.

We have so much more to do,

but by working with our suppliers,

manufacturers

on these initiatives,

our goal is to clear the way

for the entire industry

and our planet to benefit.

Another sustainability goal is

simply reducing the amount of hardware

you need to buy,

in the first place.

What if you didn't need

to upgrade a bulky,

new game console

every few years?

With Stadia we're actually

consolidating devices,

so the only hardware you need

is a controller and a screen

to play your games

anywhere, any time.

To give people

a great gaming experience,

we designed the first

cloud-based controller.

You know, great design isn't just

about how something looks.

It's also about how it feels,

and subtle design differences

can have a profound effect.

And we wanted the controller

to be comfortable

in the hands of all gamers.

We found design inspiration

in some unlikely places.

Thurston: Hey.

Pi: How's it going?

Thurston: Good, man. Nice to meet you.

Pi: Come on in.

Thurston: All right.

Pi: When I go to these

really nice kitchens

they all have

these simple knives.

Like, none of them look like

the grocery store knives...

Thurston: Yeah.

Pi: With all the grips and details.

It's really uncomfortable,

if you rotate your hand around.

The reason why most

professional kitchens

have knives like this

is you can use it in many ways,

so that is a starting point

for the controller.

We literally took a knife handle,

and we bent it.

It's like, "Oh,"

like we're on to something.

Thurston: Yeah.

Pi: So from there, that one ancestor

basically had hundreds

and hundreds of kids.

I kept building on it patiently.

Thurston: Yeah.

Pi: Until it became that, and it's made

for small and large hands,

so it's super usable

for a large segment of gamers...

Thurston: Yeah.

Pi: That aren't always appreciated.

Chanen: Jason was very, very insistent

that we have a non-visible screw design.

Pi: It's super important to give it

that nice, clean look...

Thurston: Yeah.

Pi: Instead of punching

a bunch of holes onto the back.

Chanen: That was one of the biggest

challenges for product design.

We think it's really worth it.

It makes it very comfortable

in the hand, and seamless, and Googley.

Thurston: Oh, wow. That was impressive.

Good work.

Ross: We worked with thousands of people

playing hours and hours of games,

to test our controller

against all of its limits.

It needs to feel right for

as many people as possible.

Putting people at the center

of our design is integral to our process

and our principles,

whether it's hardware or software,

creating truly helpful products

for people starts with empathy.

One of our earliest projects

we tackled within hardware team

was designing

a new kind of laptop

that could deliver performance

and versatility

in a truly beautiful form.

We wanted to physically

embody the speed and simplicity

that people love

about Chrome OS.

The result was the original Pixelbook.

The response was great.

People really love

the award-winning design,

the keyboard, and the speed.

So over the past couple of years,

we've been working really hard

to bring that kind of experience

to even more people,

at a more affordable price.

I actually believe

that you can be more creative

when designing within constraints,

so once again, we started

with our users' needs,

especially portability

and battery life.

We wanted to create a thin

and light laptop

that was really fast

and also have it last all day.

And of course, we wanted it

to look and feel beautiful.

We landed on Pixelbook Go.

The design is so distinctive

with an incredibly light magnesium

that lets us create a very smooth,

matte finish in great colors.

Pixelbook Go comes in

just black and not pink,

one of the iconic colors

we introduced on Pixel 3,

and we created a new rippled,

wavy bottom that's easy to grip.

Pixelbook Go is lighter

than Pixelbook,

but we still managed to add a battery

that is 15% larger,

making it easier

to keep working all day.

We also spent a lot of time

making sure the keyboard

is comfortable and quiet.

We took all of our learnings

from the original Pixelbook

and really refined the design.

We ended up with keys

that feel great to use

and are even quieter

than the original.

And with Chrome OS, Pixelbook

Go is always fast, secure,

and all your devices

stay in sync with each other.

Everything about Pixelbook

Go is designed to address

real user needs,

for an affordable price.

You can preorder it now

in just black with not pink coming soon.

Next up, my colleague

Rishi Chandra will tell you

about the work

we've been doing to make life

at home a little easier.

Thank you.

Chandra: Hey, everyone. I'm excited

to give an update on Google Nest

and our mission

to create the helpful home.

So last month we launched

Nest Hub Max

which is a great example

of the power of ambient computing.

See your photos come to life

with a screen

that automatically adjusts

to your lighting conditions.

Pause your music and videos

with a simple hand gesture.

And it automatically adjusts

the information and controls,

based on your proximity

to the device.

At Nest, we want to put people first

and build technology around their needs.

It's the difference between just being

smart and being truly helpful.

So while the rest of the industry's

focused on standalone devices,

our focus is on building

whole home solutions

that bring together technology

to provide real help for real homes.

And the most important place

to get this right is privacy.

It's your home. The most personal,

private space in your life.

So in May, we published

a clear set of privacy commitments

which helps you understand

how our technology works.

Today, we want to share how these

commitments extend beyond Google,

to our third-party ecosystem

of partners.

So we're announcing

an update to our Works

with Google

Assistant program.

We're working with partners

to migrate their working Works

with Nest integrations

that people know and love,

but doing it built on a foundation

of privacy and security.

For example, we're requiring partners

to pass a security review,

before they can even request

access to your Nest devices.

You should have confidence

in how Google and its partners

are protecting your home data.

And then you can focus on,

instead,

the great benefits

of the helpful home.

For example,

let's talk about home audio.

It used to cost thousands of dollars

and a professional installation,

if you wanted seamless audio

throughout your home.

Well, Google changed all that

with a whole-home audio solution

that is simple, affordable,

and sounds great.

It started several years ago

with the launch of Chromecast,

making it easy to use

your phone or your voice

to play content

on your favorite devices.

And with Google Home Mini,

home audio got even more affordable

with a great-sounding speaker

with multi-room support.

And with Nest Hub Max,

you now have a home media control center

right on your smart display.

And it all works seamlessly

together with stream transfer

where you can naturally move

content around your home.

So for example,

I can start a playlist

or watch a show on my Nest Hub Max

in the kitchen,

and when I'm done cooking

just say,

"Hey, Google. Move this

to the living room TV."

And it'll pick up right

where I left off.

It's really easy.

Now, for a lot of people,

Google Home Mini

was a perfect starter kit

for your audio system.

And today, we're introducing

the next generation--Nest Mini.

It's even more capable with

the same affordable price point

and the same iconic design.

So let's start with the design.

Colors really help Mini blend

naturally into your home,

and you now have

a new color option called sky.

And as Ivy mentioned,

all of our fabric is made from 100%

recycled plastic bottles.

Now, we also heard from you.

You want a little more flexibility

of where to place Mini,

so we added

a simple wall mount.

It really looks great

anywhere in your home.

Now, the original mini

was designed to pack

in great sound

in a really small form.

And with Nest Mini you get

even better-quality sound.

2X stronger bass and even

more clear and natural sound.

And for those times

when your home gets loud,

like it does at mine,

we added a third mike,

to hear you better

in noisy environments.

Nest Mini also got

a really cool new superpower.

There's a dedicated machine

learning chip

with up to one

TeraOPS of compute.

So for the first time, core experiences

of the Google Assistant

can come from the datacenter

and be moved,

instead, to run locally

on your device.

Simply put, things are

gonna get a lot faster,

as it learns

your family's frequent commands.

Finally, Nest Mini also powers an

amazing home communication system.

A home intercom,

so you can talk room to room.

A home alert system telling you

who's at the front door.

A home phone allowing you

to call anyone in the world,

for free,

using Google Duo.

I can even use my phone

to call my Nest devices.

It works great for those

times I'm leaving work,

and I want to ask the family

what they want for dinner.

So that's the new Nest Mini.

Our next step in bringing

seamless audio and communication

to more homes

around the world.

Okay. Now, let's talk

about home awareness.

One of our core products

is Nest Aware which,

combined with our Nest cams,

provides intelligent alerts

and camera history.

Now, lots of our users

have multiple cameras,

and we've heard from you

that our Nest Aware

pricing can get a little

expensive and complicated.

So today, we're announcing

a new whole home pricing model.

For one monthly rate,

you get Nest Aware support across

all your Nest devices

in your home.

So whether you have two cameras

or you have ten cameras,

you pay the same

monthly rate.

And you can choose between

two different pricing plans,

depending on your needs.

We even added more video history.

The new Nest Aware will be

rolling out early next year,

and it'll be easy to switch

over your existing plan.

Now, as part of the new

Nest Aware subscription,

we're also unlocking the power

of speakers and displays,

to be a part

of your home awareness system.

So devices like Nest Mini

or Nest Hub

can be your ears when you're

on the road or on vacation.

We use on-device AI--sound detection

AI--to pick up critical sounds,

like barking dogs or smoke

and carbon monoxide alarms,

and we send an alert

to your phone.

So now, in one go, even those basic

smoke alarms become smart smoke alarms.

And when you get an alert

you have the option

to her the alert or listen live,

to confirm the alarm.

Now, if it is an emergency,

the home app can directly connect you

to the 911 call center

closest to you,

regardless of where

in the world you are.

So in those critical moments,

the last thing you want to do

is scramble to find

a local emergency dispatcher.

Now, these notifications

will be part of the new

Home app which actually includes

a new feature called the home feed.

It brings together all the notifications

and snippets

from your devices, organizes 'em,

and highlights the important stuff,

so you can quickly see priority items,

or you get a general recap of the day.

So that's the new Nest Aware.

More affordable with more features

and support for more devices.

Okay. Finally, let's talk

about home connectivity.

You can have the best home setup

in the world,

but it's nothing without great

Wi-Fi coverage.

That's why we launched Google

Wi-Fi three years ago, and since launch,

it has been the number one selling mesh

Wi-Fi system on the market.

And in 2019, it is the top-selling

router of any kind,

and it's a router that actually gets

better over time with automatic updates,

to add parental controls,

improve performance,

and enable Google's

latest security features.

Well, today, we're also updating

the hardware with Nest Wi-Fi.

Now, the Nest Wi-Fi system's

actually two devices.

The router plugs into your modem

and creates a powerful home network.

The point expands

your coverage.

Now, working together

they create a single,

strong Wi-Fi connection

throughout your entire home.

And our updated hardware

and software delivers

up to 2X the speed

and up to 25% better coverage.

So now, the Nest Wi-Fi system

only needs one router and one point,

to cover around 85% of homes

in the U.S.

Now, we're also solving a common problem

you find with routers today.

Most of them get hidden

in a closet or cabinet,

because truthfully,

they're pretty ugly

which reduces their signal

intention by 50%.

Nest Wi-Fi is designed

to be out in the open

where it performs at its best

with a range of colors

that'll naturally blend

into your home.

And of course,

it's really simple to use.

With the Google Home app you can set up

your Nest Wi-Fi network in minutes,

and once you're set up,

it's easy to share your Wi-Fi password,

manage your network,

set a schedule for the kids,

or create a guest network.

Nest Wi-Fi also provides a foundation

for your smart home connectivity.

We're working with

a growing list of partners

to enable seamless setup

in the Home app.

And with support for BLE

and Thread we can talk

to smart home devices locally,

so you don't have to buy

a separate hub.

Stay tuned for even more partner

announcements, over the next few months.

Lastly, we added a Google Assistant

smart speaker to the Nest Wi-Fi point,

so it does everything

the Nest Mini does.

Plays your music with great sound,

provides answers to your questions,

and lets you control smart

devices with just your voice.

So now, you can broadcast a message

to your kids that it's time for dinner.

And if that doesn't work,

try saying,

"Hey, Google, pause

Wi-Fi for kids' devices."

Pretty sure that'll work.

So that's the new Nest Wi-Fi.

Better coverage, smart home support,

and the Google Assistant.

It'll be available

starting on November 4th.

With new, affordable home solutions

for audio, awareness, and connectivity,

everyone now can start building

their own helpful home.

Thank you.

female announcer: Right now,

in Mountain View, it's 68 and sunny.

Today, it'll be sunny

with a forecasted high of 72,

and a low of--

Kwee: Hey, Google. Volume ten.

Hey, John.

Can you come here for a sec?

Thurston: So you use this room to test?

Kwee: Right, so we use this type

of setting

to really stress

the microphones.

Thurston: Okay.

Kwee: Right now,

I'm talking to it this way,

but sometimes our devices are higher,

and sometimes they're lower, you know?

Thurston: 'Cause I might be down here.

Kwee: Yeah, exactly.

You know, because it's gonna

be in so many rooms,

it's sort of a privilege

to, you know,

like--but we gotta get

this right, you know?

Thurston: Yeah.

Kwee: I come from a family

of immigrants,

and they all have accents.

And it's important for me

to design products

that, you know, my parents can use

and that it works for everyone.

At Google, like, everyone sort of

has their slogan of, like,

what their passion is.

And on mine it's actually, "Be heard."

It obviously goes into, like,

the stuff that I work on,

but also, you know, speaking up

when things don't feel right.

What this represents is an entire

Google team's voice of,

"We got here,

because we worked together."

Thurston: You know what's kind of cool

about that is when multiple voices

come together to express sound

in a coherent and beautiful way.

Kwee: Yeah?

Thurston: We call that harmony.

Kwee: There you go. Harmony. With Wi-Fi.

Ellis: Hi.

I'm Sabrina, from the Pixel team.

Now, let's talk about

how Google's ambient

computing vision comes to life

when you're on the go.

Pixel 4 introduces entirely

new helpful experiences

with more natural interactions.

It's completely redesigned

with a new look, a new color,

and a beautiful new finish.

And Pixel 4 includes camera

features and sensors

that you're not gonna find

on any other phone.

Let's start there.

Five years ago,

our advanced technologies

team began its project Soli,

to investigate radar capabilities.

Radar's been around for a long time,

and it's still one of the best ways

to sense motion.

It's precise, low power,

and it's fast.

There were lots of

exciting possibilities,

but here's what our first sensor

looked like

when we started working on Soli.

Radar sensors have always been way

too big to fit in a phone,

so we shrunk it down into a tiny chip,

but that still wasn't small enough.

So we had to shrink

it down even more.

Pixel 4 is the first smartphone

with a radar sensor.

It powers the new motion

sense capabilities,

for more human interactions

with your phone.

For instance, Pixel 4 has the fastest

secure face unlock on a smartphone,

because the process starts before

you've even picked up your phone.

Motion sense prepares the camera

when you reach for your Pixel 4,

so you don't need to tap the screen.

It's so much faster and smoother.

Motion sense can power down your phone

when you walk away

and turn it back on

when you approach your phone.

It also lets you control your Pixel

with simple gestures.

Swipe to skip a song. Silence a call.

Wave hello to Pikachu.

And the Soli team is working on

a wide range of helpful new features,

from gaming to personal wellness.

Here's a quick look.

Giusti: It's a very famous saying

that any advanced technology

becomes indistinguishable from magic.

That's one of the things

we talked about with Soli.

It's a magical sensor.

Thurston: I did it!

I touched without touching.

Lien: Radar has a lot of very

interesting properties

that would be very useful

for human/computer interaction.

You can shrink it down.

Thurston: All of this is now in there?

Yes.

Lien: That's right. Yeah.

It can sense through materials.

It's extremely sensitive, for motion.

Thurston: Yeah.

Giusti: And so we built this

new interaction paradigm,

based on the understanding

of body language...

Thurston: Yeah.

Giusti: Distances, and gestures.

Poupyrev: How can we make the language

interaction with technology

closer to what we do naturally,

in the real world?

Giusti: Then, of course,

we really need to test,

to distinguish between intentional

and unintentional gestures.

Just because I wave

on top of the device...

Thurston: Yeah.

Giusti: Doesn't mean that I want

to skip a song.

If I pick up coffee cup, this gesture

is very similar to a swipe.

And this is really important,

and I can do this...

Thurston: Whoa.

Giusti: And it actually works.

With Soli we can try

to understand

more about the implicit behavior

that happen around the device.

Thurston: The phone knows earlier

what your intention is.

Giusti: Exactly. Let's say

the alarm goes off.

Really annoying.

Thurston: Yeah.

Giusti: As you reach,

we can lower the volume.

Thurston: Ahh.

Giusti: The phone is more polite,

and then you can just go gesture,

to shut it off.

This moment of understanding

each other

happen all the time, between us,

but they never happen with technology.

What we can do with the radar

is to actually capture aspect

of non-verbal communication.

And as a first step,

in Pixel 4, with motion sense,

is to get us close as possible to the

intuitive-ness of verbal interaction.

Thurston: Silence.

Ellis: Since the Soli sensor can detect

the environment around Pixel 4,

privacy had to be built in,

from the start.

You can turn motion sense

on or off, at any time.

And when it's on all of the sensor's

data is processed right on your Pixel.

It's never saved or shared

with other Google services.

And motion sense

isn't the only way

we're making your phone interactions

faster and more natural.

The Google Assistant is now

deeply integrated into Pixel 4's OS

and across your apps.

You can quickly open apps,

search across your phone,

share what's on your screen,

and a lot more.

The Assistant can simplify

multitasking, too,

with a clean, new interface.

Check this out.

Just give Pixel 4 a quick squeeze.

Show me Maggie Rogers, on Twitter.

What are her concert dates?

Share this with Vivian.

Reply, "Let's go see her."

Open ticketmaster.com.

Search for

Maggie Rogers events.

A key way we're making

the assistant this fast

is with an on-device version

of our language models

that run in our datacenter,

so they can run locally,

right on your Pixel 4.

This means the new assistant

uses a hybrid model.

It can respond to many day-to-day

requests on device,

like starting a timer

or connecting for requests like,

"Is my flight on time?"

You also have new ways

to manage your data.

Choose a time limit for how long

you want your activity data

to be saved

in your Google account,

or just tell the assistant to delete

everything you sent to it today,

or this week, and it will.

You're in control, and you can

ask it more details by asking,

"Hey, Google, how do you

keep my data safe?"

We're taking the same care

to protect your on-device data, too,

with Titan M

and other security features.

Last year's Pixel 3 scored the highest

for built-in security for a smartphone,

according to Gartner.

We built Titan M into Pixel 4, as well,

to protect your most sensitive

on-device data,

like your passwords, your OS data,

and now, your face unlock model.

Your phone has some of your

most personal, private information,

and we have a responsibility

to keep it safe and secure.

Now, how many of you have tried

a voice recorder app?

I know I've tried

a few thinking,

"I'll be able to get organized

by recording notes to myself,

interesting lectures,

important events,"

but then I end up with a bunch

of untitled audio clips

that I really don't know

what to do with.

So we created a new kind

of audio recorder

that taps into our speech

recognition and AI.

Let's see it in action.

We've had a Pixel 4 recording the show,

for the past few minutes.

As you can see,

with one tap I can get recorder

transcribing my words,

in real time, as I'm saying them.

Now, to show this is live,

it is now 10:44.

And it's pretty accurate.

This means you can transcribe meetings,

lectures, interviews,

or anything you want to save.

Eric, backstage, is going

to save this recording.

And now, I can go into the search bar

and find whatever I'm looking for.

I can search for sounds,

words, phrases.

Let's see all the times

I've mentioned Pixel,

across my entire library of recordings.

The places where the word "Pixel"

are said are highlighted in yellow,

in the playback bar,

so you can dive into the exact part

of the recording you're looking for.

It's pretty cool, and you'll notice

this phone is actually in airplane mode.

All this recorder functionality

happened on device.

Now, I want to take a minute

to talk about Pixel 4's OLED display.

DisplayMate has awarded

Pixel 4 XL their highest score,

an A+ rating, together with

the best smartphone display award.

In five key areas, like color

accuracy and image contrast,

DisplayMate

classified Pixel 4

XL's display as visually

indistinguishable from perfect.

Pixel 4 is also our first smartphone

with a 90

Hz refresh rate,

and we've added some smarts.

The refresh rate adjusts on its own,

depending on what you are doing,

so you get a great visual experience

while still preserving battery life.

Pixel 4 brings together so many helpful

new technologies and capabilities,

and you'll get the best

Android experience with Android 10.

And you're the first in line to get

the latest OS updates and features.

We also want to make sure you get

the best experience out of the box,

so Pixel 4 comes with

three months of Google

One for new, eligible members.

You get lots of premium features,

including pro sessions,

for one-on-one virtual help.

So if you have a question

about your settings

or want a few tips for the camera,

we are there for you.

The new Pixel comes

in three colors--just black,

clearly white, and a limited edition

called oh so orange.

It also comes in two sizes,

both with the same features,

and both available

for preorder starting today.

Shipping starts on October 24th.

And we're excited that people will be

able to find Pixel in even more places.

We're expanding

our carrier partnerships,

so Pixel 4 is now available

through every major U.S. carrier.

Now, we didn't forget about the camera.

For the past three years,

Pixel set the standard

for smartphone cameras

with incredible capabilities,

like HDR plus, super res zoom,

top shot, and of course, Night Sight.

With Pixel 4 we're raising

that bar yet again,

and it all starts

with this little square.

Basically, a miniaturized camera

rig right on the back of your phone.

You can see the rear, wide,

and telephoto cameras,

a hyper spectral sensor,

a mike for your videos

and Instagram stories,

and a flash that we hope

you'll use mostly as a flashlight.

But it's there, just in case.

But the hardware isn't what makes

our camera so much better.

The special sauce that makes

our Pixel camera unique

is our computational photography.

And who better to talk about it

than Professor Marc Levoy,

from Google Research?

Levoy: Thanks, Sabrina.

It's great to be here.

There's a saying

among photographers

that what's important to taking

a great picture is,

in order, subject, lighting, lens,

and the camera body.

It's their way of saying

that it doesn't matter

which SLR body you use,

unless you get the first

three elements right.

Well, here's a slightly different

take on this list.

Subject, lighting,

lens, software.

So by "software" I mean

computational photography,

so what does that mean?

It means doing less with

hard-wired circuitry and more with code.

I like to call it

a software-defined camera.

It typically means capturing

and combining multiple pictures,

to make a single, better picture.

One version of this is HDR plus.

The technology we've used for

taking photos on every Pixel phone.

When you tap the shutter button

we capture a burst of up

to nine pictures.

These pictures

are deliberately underexposed

to avoid blowing

out highlights.

We align them using software

and average them

which reduces noise

in the shadows.

This lets us

brighten the shadows,

giving you detail in both

the highlights and the shadows.

In fact, there's a simple formula.

Noise goes down as the square root

of the number of images

you average together.

So if you use nine images,

you get 1/3 as much noise.

This isn't mad science.

It's just simple physics.

By the way, on the left

is our raw output,

if you enable that in the app.

There's something else about this list.

It says the lens is important.

Without quibbling

about the order on the list,

some subjects are farther away

than you'd like,

so it does help telephoto shots

to have a telephoto lens.

So Pixel 4 has a roughly

2X telephoto lens,

plus our super

res zoom technology.

In other words, a hybrid

of optical and digital zoom

which we use on both the main

and telephoto lenses,

so you get sharp imagery

throughout the zoom range.

Here's an example.

You probably think this is a 1X photo.

It's not. It's a zoom taken

from way...back...here.

By the way, super res zoom

is real multi-frame super resolution,

meaning that pinch zooming

before you take the shot

gives you a sharper photo

than cropping afterwards,

so don't crop like this.

Compose the shot

you want by pinch zooming.

Also, by the way, most popular

SLR lenses do magnify scenes,

not shrink them.

So while wide angle can be fun

we think telephoto is more important.

So what new

computational photography features

are we launching with Pixel 4?

Four of them. First, live HDR plus.

Everyone here is familiar

with HDR plus' signature look

and its ability

to capture extreme brights

and darks in a way

that looks crisp and natural.

But even phones with good HDR solutions

can't compute them in real time,

so the viewfinder often looks

different from the final image.

In this example,

the window is blown out,

on the viewfinder, which might tempt you

into fiddling with the exposure.

This year, we're using machine

learning to approximate

HDR plus in the viewfinder,

so you get our signature look

while you compose your shot.

We call this feature

live HDR plus,

so the industry's most successful

HDR solution is now real time

and WYSIWYG--what you see

is what you get.

Now, if we have

an intrinsically HDR camera,

we should have HDR controls for it.

So Pixel 4 has dual exposure controls.

Here's an example.

This is a nice HDR plus shot,

but maybe you would like

to try it as a silhouette.

So you tap on the screen,

and lower the brightness slider a bit.

That mainly changes

the capture exposure.

Then you lower

the shadow slider a lot.

That mainly changes

the tone mapping,

and voila, you get

a different artistic vision.

Try doing that

with any other cell phone.

So separate sliders

for brightness and shadows

while you compose your shot.

It's a different way of thinking

about controlling exposure in a camera.

Second, white balancing

in photography is a hard problem.

Mathematicians call it

an ill-posed problem.

Is this snow blue, the way

this SLR originally captured it,

or is it white snow

illuminated by a blue sky?

We know that snow is white.

With enough training so can the camera.

We've been using learning-based white

balancing in Night Sight since Pixel 3.

In Pixel 4, we're using it

in all photo modes,

so you get truer colors,

especially in tricky lighting.

Here's a tough case.

An ice cave.

It's blue light,

but not a blue person.

And here's what it looks like

with Pixel 4's white balancing.

Third, we've continued

to improve portrait mode

with our dual pixel

or split pixel technology.

We've always been good

at portraits and at macro shots.

This year, we're computing depth,

again using machine learning,

from both dual pixels

and dual cameras,

which gives us accurate

depth farther from the camera.

This extends portrait mode

to large objects

and stand-further-back portraits.

We also have a luscious

new SLR-like boke.

That's the shape of the blur.

Look at the lights

on either side of her head.

We're doing better on hair

and dog fur which are hard.

And of course, we still

do great selfie portraits.

Fourth and last, we have continued

to improve Night Sight,

in many ways,

and extended it to a use case

that has always been sort of

a holy grail, for me.

You could have taken this dusk

shot using Pixel 3 last year.

Using Pixel 4 you can

take this nighttime picture,

from the same viewpoint.

In the year

since we launched it,

Night Sight has been called everything

from fake to sorcery.

Well, it's neither.

Think back to the mathematics

that I explained at the beginning.

Astrophotography is about taking

longer exposures and more of them.

Up to 16 seconds times

15 exposures.

That's four minutes,

but it's a single shutter press,

and it's fully automatic.

By the way, you can't do this

with a single long exposure.

In four minutes, the stars do move,

and trees wave in the wind.

So you need robust alignment

and merging of multiple pictures.

And for a four-minute exposure,

we do recommend a tripod,

or you can prop

your phone on a rock.

Is there machine learning?

Yes.

We use it for white balancing,

as I mentioned.

We also use semantic segmentation

in all our photo modes

and have for years,

to brighten faces in HDR plus,

a feature we call

synthetic fill flash,

to separate foregrounds

from backgrounds, in portrait shots,

and to darken and de-noise

skies in Night Sight.

Is there computational photography?

There's lots of that too.

Digital sensors are prone to hot pixels

that are stuck at red, green, or blue.

The longer the exposure

the more hot pixels.

Our exposures are pretty long,

so we need some clever algorithms

to remove those hot pixels.

By the way, that's our

astrophotography field testing team.

And yes, they sat still

for a long time, for this shot.

So where does this game stop?

What can't we capture, using Pixel 4?

Well, we can capture the moon which,

by the way, required some fiddling

with those dual exposure

controls I told you about.

And we can capture

a moonlit landscape.

This is not daytime.

It's the middle of the night,

and the landscape is illuminated

only by the moon.

See the stars?

But what we can't do,

including on Pixel 4 today,

is capture both at once,

in the same picture.

The problem here is

that the moon is blown out,

and the Marin headlands, at the bottom,

are just a silhouette.

The dynamic range--the difference

in brightness between a full moon

and a moonlit landscape

is 19 F stops.

That's 19 doublings.

About half a million times brighter.

Way beyond the range of any

consumer camera, even an SLR.

So is this scene forever

impossible with a cell phone?

Remember what I said at the beginning,

about software-defined camera.

Pixel is committed to making its cameras

better with software updates,

so stay tuned on this one.

To sum up, four new

computational photography features.

Live HDR plus with dual

exposure controls.

Learning-based white balancing.

Wider-range portrait mode

with an SLR boke

and Night Sight

with astral photography.

Oh, and remember,

you can use Night Sight

for many things

besides stars.

Many things, so go out there,

and be creative with Pixel 4.

Now, it's my honor to introduce

one of my favorite artists

who has spent her career creating some

of the most memorable photographs

of the last 50 years.

12 months ago, we gave her a Pixel,

and she's taken it all over the country,

to build a new collection of portraits.

She also gives us suggestions

and candid feedback

which we've taken to heart,

in the tuning of the Pixel 4 camera.

So please welcome

my friend Annie Leibovitz,

along with our own Lily Lin.

Lin: Thank you, Marc. Hi, Annie.

Leibovitz: Thank you, Marc.

Thank you, Marc. Thank you, Marc.

Lin: Thanks for joining us today.

Leibovitz: This is an extraordinary

opportunity that Google gave me,

and I've always been interested

in the camera phone

and, you know,

what it could do

and what it--you know,

what its potential was.

And Google came to me

and said,

"We'd like to support you in

some sort of artistic endeavor,"

and we thought of this project.

And I mean it's obvious

the--what's interesting

about a camera phone,

I mean, is you can carry it

in your pocket, for example.

But go ahead. I'm sorry.

Lin: No, no. It's great.

I know that you've been using

the camera for over a year now,

to shoot a collection

of photographs.

Some of which we're seeing

the behind-the-scenes here.

Can you tell us more

about the project?

Leibovitz: Well, we started really

with the Pixel 3,

and you know, I was very,

you know, suspicious

and, you know,

very careful with it.

And it really became an exercise

in light,

and composition, and content.

And then when the Pixel 4

came along

I was kind of very impressed

about how I relaxed with it,

and just glided with it,

and used it,

and really just enjoyed

taking pictures.

I'm really towards the end of--I mean

we're going to be doing more work,

but towards the end of the work

that we were doing I felt like

I was just beginning

to sort of get it.

And I just let the camera

do the work,

quite honestly,

and really enjoyed myself.

But the project--the

people--I mean--

Lin: Some of which we have here today.

Noor, and Chase, and Idris.

Leibovitz: Noor and Chase--I just...

It's incredible.

I mean, the people made the project.

We really turned to people who care,

and people who matter,

and people who are doing things

that give us hope across the board.

And you know, every single person

that we photographed

is doing something that they care

about what they're doing,

and they represent, you know,

great parts of us

who are getting on with it,

you know?

Lin: Change-makers I think is what

I've heard you call them.

True change-makers around the country,

so you've been traveling.

Speaking of country--traveling

across the country

shooting these

amazing subjects.

Leibovitz: When Google first came to me,

you know, they sort of totally

seduced me by saying,

"Would you like to drive

across the country?"

And then, you know--and that

turned into, of course, you know,

going back to people, so--

Lin: Yeah. It's great.

Leibovitz: If you see what I did

was I decided to take two photographs,

to create a portrait,

and 'cause it's hard to say

what you want to say about a person,

especially these extraordinary

people, in one picture.

And so I made it a diptych

and took two photographs,

for example, with Sarah Zorn,

from the Citadel.

There's a photograph of her,

you know,

almost on graduation day,

in her uniform.

But next to her is a photograph

of the boots

she wore for four years,

you know, every single day so.

Lin: Well, so I have to ask.

I'm so curious, because you have access

to the world's best camera equipment,

so how is it different

with this project,

just having what you have

in your pocket now?

What is that experience like?

Leibovitz: Well, I've been using,

like everyone else,

you know,

camera phones for a while.

And the whole idea was,

"Can you use it to go out

and do work, as a photographer?"

And I was dying for this,

to be given this opportunity,

by Google, to sort of develop,

you know, the camera phone

for a photographer and how to use it.

And you know, as I said before,

it was a little bit of a rough start,

and then I just relaxed,

and I really--totally enjoying myself.

One of the last shoots with Meg,

the soccer player,

it really felt like

we were just floating.

Lin: Yeah.

Leibovitz: I mean she was really

a beautiful--anyway,

she was just a beautiful muse,

and I took these photographs

that I wasn't really thinking

about the camera

or thinking, you know,

just really composing.

And the light was beautiful,

and she had that red shock of hair,

and you know--

Lin: It's great.

Leibovitz: You just--it was great.

Lin: That's right.

Well, so before we go,

since I have you, I have to ask.

What pro tips do you have

for all of us here

who want to take beautiful images

like this with the phone in your pocket?

Leibovitz: Oh, it's all inside you.

I mean you just go out,

and you do it, and it's all there.

I think what's great about,

you know, the camera

phone--I mean

my children use this camera,

and I mean we all

are using this camera.

And it's a brand new language,

and you know,

if you want to do something

more specific,

then, you know, you may

fall into another category,

and you are a photographer.

But it's just really great that this

is available for everyone to use.

Lin: Yeah.

The democratization of photography

is what I've heard you call it so--

Leibovitz: I think it's great.

Lin: Thank you so much, and thank you.

I wish we had more time,

but I know you, as well as Noor,

Chase, Idris are gonna be sticking

around, so thank you for that.

Thanks for joining us onstage,

and guys, Annie Leibovitz.

Leibovitz: Okay. Thank you.

Osterloh: Thank you so much, Annie.

Amazing project. We're all huge fans.

That was awesome.

Well, as you've seen today,

our vision for ambient computing

is to create a single,

consistent experience

across your home,

your work, and on the go.

It's available anywhere you

want it whenever you need it.

With the introduction

of our new Pixel phone,

Pixel buds, Pixelbook Go, Nest Mini,

Nest

Wi-Fi we're taking

a big step

towards this vision

with much more to come.

And we couldn't get to all

the product experiences today,

so if you're here with us,

in New York,

there'll be a lot more product details

to see upstairs, in person.

And for those on the live stream,

please go to the Google store online.

See a lot more.

Thanks so much for joining us today,

and we'll see you again soon.

Thank you.

Person: Guess what?

We play it louder.

Louder. Bigger, better, prouder.

Ramp up the volume.

Turning up the power.

Guess what?

Guess what? Right?

Guess what? Guess what?

Person: Hey, Google.

Turn it up.

Person: Louder. Louder. I feel good.

I feel good.

Person: Oh, yeah,

yeah, yeah, yeah, yeah.

Person: I feel nice. I feel nice.

Person: Oh, yeah, yeah,

yeah, yeah, yeah.

Person: I feel ready. I feel ready.

Person: Oh, yeah, yeah,

yeah, yeah, yeah.

Person: Yeah that's right.

Yeah that's right.

